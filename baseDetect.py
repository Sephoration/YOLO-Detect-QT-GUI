# æ£€æµ‹ç»“æœæ¸²æŸ“åˆ°å±•ç¤ºçª—å£ 
# æ ¹æ®æ£€æµ‹æ¡†åˆ—è¡¨ï¼Œåœ¨åŸå§‹å›¾åƒä¸Šç”»æ¡†ä¸æ ‡ç­¾
# åˆ†ç±»æ£€æµ‹ã€ç›®æ ‡æ£€æµ‹ã€å…³é”®ç‚¹æ£€æµ‹



import cv2
import numpy as np
from typing import Dict, Any, List, Tuple, Optional


class BaseDetect:
    """
    é€šç”¨åŸºç¡€æ£€æµ‹æ¸²æŸ“å™¨
    
    æ”¯æŒä¸‰ç§æ¸²æŸ“æ¨¡å¼ï¼š
    1. âœ… ç›®æ ‡æ£€æµ‹ï¼šç»˜åˆ¶è¾¹ç•Œæ¡†ã€ç±»åˆ«æ ‡ç­¾ã€ç½®ä¿¡åº¦
    2. âœ… å›¾åƒåˆ†ç±»ï¼šåœ¨å·¦ä¸Šè§’æ˜¾ç¤ºåˆ†ç±»ç»“æœï¼ˆç®€æ´åˆ—è¡¨ï¼‰
    3. âœ… å…³é”®ç‚¹æ£€æµ‹ï¼šç»˜åˆ¶è¾¹ç•Œæ¡†ã€å…³é”®ç‚¹ã€éª¨æ¶è¿æ¥ï¼ˆé€šç”¨åŒ–è®¾è®¡ï¼‰
    
    å…³é”®è®¾è®¡ç‰¹ç‚¹ï¼š
    1. ä¸å‡è®¾ä»»ä½•ç‰¹å®šæ¨¡å‹ï¼ˆå¦‚17ä¸ªäººä½“å…³é”®ç‚¹ï¼‰
    2. æ ¹æ®å®é™…æ¨¡å‹ä¿¡æ¯åŠ¨æ€æ¸²æŸ“
    3. é…ç½®é©±åŠ¨ï¼Œå¯é€‚åº”ä¸åŒå…³é”®ç‚¹æ¨¡å‹
    4. æ‰€æœ‰æ¸²æŸ“éƒ½åœ¨å›¾åƒè¾¹ç•Œå†…
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–é€šç”¨æ¸²æŸ“å™¨
        
        Args:
            config: æ¸²æŸ“é…ç½®å­—å…¸ï¼Œå¯é€‰
        """
        # é»˜è®¤é€šç”¨é…ç½®
        self.config = {
            # é€šç”¨å­—ä½“é…ç½®
            'font': cv2.FONT_HERSHEY_SIMPLEX,
            'font_scale': 0.5,
            'font_thickness': 1,
            'text_color': (255, 255, 255),  # ç™½è‰²æ–‡å­—
            
            # é€šç”¨é¢œè‰²ç”Ÿæˆé…ç½®
            'color_generation': {
                'hue_step': 30,  # è‰²ç›¸æ­¥é•¿
                'saturation': 255,
                'value': 255
            },
            
            # ç›®æ ‡æ£€æµ‹é…ç½®
            'detection': {
                'bbox_thickness': 2,
                'label_background': True,  # æ˜¯å¦æ˜¾ç¤ºæ ‡ç­¾èƒŒæ™¯
                'default_bbox_color': (200, 100, 0)  # é»˜è®¤æ¡†é¢œè‰²
            },
            
            # åˆ†ç±»é…ç½®
            'classification': {
                'position': (10, 30),           # å·¦ä¸Šè§’èµ·å§‹ä½ç½®
                'line_spacing': 25,             # è¡Œé—´è·
                'top_result_color': (0, 255, 0), # ç»¿è‰²ï¼ˆæœ€é«˜ç½®ä¿¡åº¦ï¼‰
                'other_result_color': (255, 255, 255), # ç™½è‰²ï¼ˆå…¶ä»–ç»“æœï¼‰
                'max_results': 5,               # æœ€å¤šæ˜¾ç¤º5ä¸ªç»“æœ
                'show_background': False        # ä¸æ˜¾ç¤ºèƒŒæ™¯æ¡†
            },
            
            # å…³é”®ç‚¹æ£€æµ‹é…ç½®ï¼ˆæ‰‹éƒ¨å…³é”®ç‚¹ä¸“æœ‰åŒ–é…ç½®ï¼‰
            'pose': {
                'bbox_thickness': 2,
                'bbox_color': (0, 255, 255),    # é»„è‰²æ¡†ï¼ˆæ‰‹éƒ¨ï¼‰
                'keypoint_radius': 5,
                'skeleton_thickness': 2,
                'skeleton_color': (255, 165, 0), # æ©™è‰²éª¨æ¶ï¼ˆæ‰‹éƒ¨ï¼‰
                'show_keypoint_names': True,    # æ˜¾ç¤ºå…³é”®ç‚¹åç§°
                'show_skeleton': True,          # æ˜¾ç¤ºéª¨æ¶è¿æ¥
                'keypoint_colors': {
                    0: (0, 255, 0),    # MCP_1 - ç»¿è‰²
                    1: (255, 0, 0),    # MCP_2 - è“è‰²
                    2: (0, 0, 255),    # MCP_3 - çº¢è‰²
                    3: (255, 255, 0)   # MCP_4 - é’è‰²
                },                              # æ‰‹éƒ¨å…³é”®ç‚¹é¢œè‰²é…ç½®
                'keypoint_names': {
                    0: "MCP_1",
                    1: "MCP_2",
                    2: "MCP_3",
                    3: "MCP_4"
                },                              # æ‰‹éƒ¨å…³é”®ç‚¹åç§°
                'skeleton_connections': [(0, 1), (1, 2), (2, 3)]  # æ‰‹éƒ¨éª¨æ¶è¿æ¥
            }
        }
        
        # æ›´æ–°ç”¨æˆ·é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰
        if config:
            self._update_config(config)
        
        # åŠ¨æ€é¢œè‰²ç¼“å­˜
        self.color_cache = {}
        
        print("âœ… é€šç”¨åŸºç¡€æ¸²æŸ“å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _update_config(self, config: Dict[str, Any]):
        """é€’å½’æ›´æ–°é…ç½®"""
        def update_dict(original, new):
            for key, value in new.items():
                if key in original and isinstance(original[key], dict) and isinstance(value, dict):
                    update_dict(original[key], value)
                else:
                    original[key] = value
        
        update_dict(self.config, config)
    
    # ============================================================================
    # é¢œè‰²ç®¡ç†æ–¹æ³•ï¼ˆé€šç”¨ï¼‰
    # ============================================================================
    
    def _generate_color(self, index: int) -> Tuple[int, int, int]:
        """
        æ ¹æ®ç´¢å¼•ç”Ÿæˆé¢œè‰²ï¼ˆé€šç”¨æ–¹æ³•ï¼‰
        
        ä½¿ç”¨HSVé¢œè‰²ç©ºé—´ï¼Œç¡®ä¿é¢œè‰²å¤šæ ·æ€§
        """
        if index in self.color_cache:
            return self.color_cache[index]
        
        hue_step = self.config['color_generation']['hue_step']
        saturation = self.config['color_generation']['saturation']
        value = self.config['color_generation']['value']
        
        # è®¡ç®—è‰²ç›¸ï¼ˆ0-179ï¼Œå› ä¸ºOpenCVçš„HSVèŒƒå›´æ˜¯0-179ï¼‰
        hue = (index * hue_step) % 180
        
        # è½¬æ¢ä¸ºBGR
        hsv_color = np.uint8([[[hue, saturation, value]]])
        bgr_color = cv2.cvtColor(hsv_color, cv2.COLOR_HSV2BGR)[0][0]
        
        color = (int(bgr_color[0]), int(bgr_color[1]), int(bgr_color[2]))
        self.color_cache[index] = color
        
        return color
    
    def _get_color_for_class(self, class_name: str, class_id: int = None) -> Tuple[int, int, int]:
        """
        è·å–ç±»åˆ«é¢œè‰²
        
        ä¼˜å…ˆçº§ï¼š
        1. é…ç½®ä¸­æŒ‡å®šçš„é¢œè‰²
        2. æ ¹æ®class_idç”Ÿæˆçš„é¢œè‰²
        3. é»˜è®¤é¢œè‰²
        """
        # é¦–å…ˆæ£€æŸ¥é…ç½®ä¸­æ˜¯å¦æœ‰æŒ‡å®šé¢œè‰²
        bbox_colors = self.config['detection'].get('bbox_colors', {})
        if class_name in bbox_colors:
            return bbox_colors[class_name]
        
        # æ ¹æ®class_idç”Ÿæˆé¢œè‰²
        if class_id is not None:
            return self._generate_color(class_id)
        
        # é»˜è®¤é¢œè‰²
        return self.config['detection']['default_bbox_color']
    
    # ============================================================================
    # ä¸»æ¸²æŸ“æ–¹æ³• - ç»Ÿä¸€å…¥å£
    # ============================================================================
    
    def render(self, analyzer_result: Dict[str, Any]) -> np.ndarray:
        """
        ä¸»æ¸²æŸ“æ–¹æ³• - æ ¹æ®analyzerçš„è¾“å‡ºè¿›è¡Œæ¸²æŸ“
        
        Args:
            analyzer_result: yolo_analyzer.pyçš„å¤„ç†ç»“æœï¼ŒåŒ…å«ï¼š
                - success: å¤„ç†æ˜¯å¦æˆåŠŸ
                - raw_image: åŸå§‹å›¾åƒ
                - data_type: æ•°æ®ç±»å‹ ('detection', 'classification', 'pose')
                - processed_data: æ ‡å‡†åŒ–æ•°æ®
                - stats: ç»Ÿè®¡ä¿¡æ¯
                - model_info: æ¨¡å‹ä¿¡æ¯ï¼ˆç”¨äºåŠ¨æ€é…ç½®ï¼‰
                
        Returns:
            np.ndarray: æ¸²æŸ“åçš„å›¾åƒ
        """
        print("ğŸ–¼ï¸ æ¸²æŸ“å™¨å¼€å§‹æ¸²æŸ“...")
        
        # æ£€æŸ¥å¤„ç†æ˜¯å¦æˆåŠŸ
        if not analyzer_result.get('success', False):
            print("âš ï¸ æ¸²æŸ“å™¨æ”¶åˆ°å¤±è´¥çš„å¤„ç†ç»“æœ")
            return analyzer_result.get('raw_image', np.zeros((100, 100, 3), dtype=np.uint8))
        
        # è·å–å¿…è¦æ•°æ®
        raw_image = analyzer_result.get('raw_image')
        data_type = analyzer_result.get('data_type', 'detection')
        processed_data = analyzer_result.get('processed_data', {})
        model_info = analyzer_result.get('model_info', {})
        
        if raw_image is None:
            print("âŒ æ¸²æŸ“å™¨æœªæ”¶åˆ°æœ‰æ•ˆå›¾åƒ")
            return np.zeros((100, 100, 3), dtype=np.uint8)
        
        # åˆ›å»ºå›¾åƒå‰¯æœ¬ç”¨äºæ¸²æŸ“
        image = raw_image.copy()
        
        # æ ¹æ®æ¨¡å‹ä¿¡æ¯æ›´æ–°é…ç½®
        self._update_config_from_model(model_info, data_type)
        
        # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©æ¸²æŸ“æ–¹æ³•
        if data_type == 'detection':
            print(f"ğŸ” æ‰§è¡Œç›®æ ‡æ£€æµ‹æ¸²æŸ“ï¼Œæ£€æµ‹åˆ°{len(processed_data.get('detection', {}).get('boxes', []))}ä¸ªç‰©ä½“")
            result = self._render_detection(image, processed_data, model_info)
        elif data_type == 'classification':
            print("ğŸ“Š æ‰§è¡Œåˆ†ç±»ç»“æœæ¸²æŸ“")
            result = self._render_classification(image, processed_data)
        elif data_type == 'pose':
            print(f"ğŸƒ æ‰§è¡Œå…³é”®ç‚¹æ£€æµ‹æ¸²æŸ“ï¼Œæ£€æµ‹åˆ°{len(processed_data.get('pose', {}).get('boxes', []))}ä¸ªäººç‰©")
            result = self._render_pose(image, processed_data, model_info)
        else:
            print(f"âš ï¸ æœªçŸ¥æ•°æ®ç±»å‹: {data_type}")
            result = image
        
        # ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'stats' in analyzer_result:
            result = self.draw_statistics(result, analyzer_result['stats'])
        
        print("âœ… æ¸²æŸ“å®Œæˆ")
        return result

    def _update_config_from_model(self, model_info: Dict[str, Any], data_type: str):
        """
        æ ¹æ®æ¨¡å‹ä¿¡æ¯åŠ¨æ€æ›´æ–°æ¸²æŸ“é…ç½®
        
        è¿™æ˜¯å®ç°é€šç”¨åŒ–çš„å…³é”®ï¼šæ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´æ¸²æŸ“æ–¹å¼
        """
        if data_type == 'pose' and 'num_keypoints' in model_info:
            num_keypoints = model_info['num_keypoints']
            
            # åŠ¨æ€ç”Ÿæˆå…³é”®ç‚¹é¢œè‰²
            if not self.config['pose']['keypoint_colors']:
                keypoint_colors = {}
                for i in range(num_keypoints):
                    keypoint_colors[i] = self._generate_color(i)
                self.config['pose']['keypoint_colors'] = keypoint_colors
            
            # å¦‚æœæ¨¡å‹æä¾›äº†éª¨æ¶è¿æ¥ï¼Œä½¿ç”¨æ¨¡å‹çš„
            if 'skeleton' in model_info and model_info['skeleton']:
                self.config['pose']['skeleton_connections'] = model_info['skeleton']
    
    # ============================================================================
    # ç›®æ ‡æ£€æµ‹æ¸²æŸ“æ–¹æ³•
    # ============================================================================
    
    def _render_detection(self, image: np.ndarray, processed_data: Dict[str, Any], 
                         model_info: Dict[str, Any]) -> np.ndarray:
        """
        æ¸²æŸ“ç›®æ ‡æ£€æµ‹ç»“æœï¼ˆé€šç”¨ï¼‰
        
        æ•°æ®ç»“æ„è¦æ±‚ï¼ˆprocessed_data['detection']ï¼‰ï¼š
            - boxes: [[x1,y1,x2,y2], ...]  # è¾¹ç•Œæ¡†åæ ‡
            - labels: ['person', 'car', ...]  # ç±»åˆ«æ ‡ç­¾
            - confidences: [0.95, 0.87, ...]  # ç½®ä¿¡åº¦åˆ—è¡¨
            - class_ids: [0, 1, ...]  # ç±»åˆ«IDåˆ—è¡¨
            
        æ¸²æŸ“æ•ˆæœï¼š
            1. ç»˜åˆ¶è¾¹ç•Œæ¡†
            2. åœ¨æ¡†çš„å·¦ä¸Šè§’æ˜¾ç¤ºæ ‡ç­¾å’Œç½®ä¿¡åº¦
            3. ç¡®ä¿æ¸²æŸ“å†…å®¹åœ¨å›¾åƒè¾¹ç•Œå†…
        """
        # è·å–æ£€æµ‹æ•°æ®
        detection_data = processed_data.get('detection', {})
        boxes = detection_data.get('boxes', [])
        labels = detection_data.get('labels', [])
        confidences = detection_data.get('confidences', [])
        class_ids = detection_data.get('class_ids', [])
        
        if not boxes:
            return image
        
        # è·å–å›¾åƒå°ºå¯¸
        img_height, img_width = image.shape[:2]
        
        # è·å–é…ç½®
        det_config = self.config['detection']
        bbox_thickness = det_config['bbox_thickness']
        show_bg = det_config['label_background']
        
        # éå†æ‰€æœ‰æ£€æµ‹ç»“æœ
        for i, box in enumerate(boxes):
            if len(box) < 4:
                continue
                
            # æå–è¾¹ç•Œæ¡†åæ ‡å¹¶ç¡®ä¿ä¸ºæ•´æ•°
            x1, y1, x2, y2 = map(int, box[:4])
            
            # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨å›¾åƒèŒƒå›´å†…
            x1 = max(0, min(x1, img_width - 1))
            y1 = max(0, min(y1, img_height - 1))
            x2 = max(0, min(x2, img_width - 1))
            y2 = max(0, min(y2, img_height - 1))
            
            # è·å–ç±»åˆ«ä¿¡æ¯
            label = labels[i] if i < len(labels) else f"obj_{i}"
            confidence = confidences[i] if i < len(confidences) else 0.0
            class_id = class_ids[i] if i < len(class_ids) else i
            
            # è·å–ç±»åˆ«é¢œè‰²
            color = self._get_color_for_class(label, class_id)
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(image, (x1, y1), (x2, y2), color, bbox_thickness)
            
            # æ„å»ºæ ‡ç­¾æ–‡æœ¬
            label_text = f"{label} {confidence:.2f}"
            
            # è®¡ç®—æ–‡æœ¬å¤§å°
            font = self.config['font']
            font_scale = self.config['font_scale']
            font_thickness = self.config['font_thickness']
            
            (text_width, text_height), baseline = cv2.getTextSize(
                label_text, font, font_scale, font_thickness
            )
            
            if show_bg:
                # è®¡ç®—æ–‡æœ¬èƒŒæ™¯æ¡†ä½ç½®ï¼ˆåœ¨è¾¹ç•Œæ¡†å·¦ä¸Šè§’ï¼‰
                text_bg_x1 = x1
                text_bg_y1 = max(0, y1 - text_height - 5)
                text_bg_x2 = x1 + text_width + 5
                text_bg_y2 = y1
                
                # ç¡®ä¿æ–‡æœ¬èƒŒæ™¯æ¡†åœ¨å›¾åƒèŒƒå›´å†…
                text_bg_y1 = max(0, text_bg_y1)
                
                # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
                cv2.rectangle(image, (text_bg_x1, text_bg_y1), 
                             (text_bg_x2, text_bg_y2), color, -1)
                
                # æ–‡æœ¬ä½ç½®
                text_x = x1 + 2
                text_y = y1 - 3 if y1 - 3 > 0 else y1 + text_height
            else:
                # ç›´æ¥ç»˜åˆ¶æ–‡æœ¬ï¼Œæ²¡æœ‰èƒŒæ™¯
                text_x = x1 + 2
                text_y = y1 - 5 if y1 - 5 > 0 else y1 + text_height + 5
            
            # ç¡®ä¿æ–‡æœ¬ä½ç½®åœ¨å›¾åƒèŒƒå›´å†…
            text_y = max(text_height, min(text_y, img_height - 5))
            
            # ç»˜åˆ¶æ–‡æœ¬
            cv2.putText(image, label_text, (text_x, text_y), 
                       font, font_scale, self.config['text_color'], 
                       font_thickness, cv2.LINE_AA)
        
        return image
    
    # ============================================================================
    # å›¾åƒåˆ†ç±»æ¸²æŸ“æ–¹æ³•
    # ============================================================================
    
    def _render_classification(self, image: np.ndarray, processed_data: Dict[str, Any]) -> np.ndarray:
        """
        æ¸²æŸ“å›¾åƒåˆ†ç±»ç»“æœï¼ˆç®€æ´ç‰ˆï¼‰
        
        æ•°æ®ç»“æ„è¦æ±‚ï¼ˆprocessed_data['classification']ï¼‰ï¼š
            - top_predictions: [('cat', 0.95), ('dog', 0.03), ...]  # å‰Nä¸ªé¢„æµ‹
            
        æ¸²æŸ“æ•ˆæœï¼š
            1. åœ¨å›¾åƒå·¦ä¸Šè§’æ˜¾ç¤ºåˆ†ç±»ç»“æœ
            2. æœ€å¤šæ˜¾ç¤º5ä¸ªç»“æœï¼ŒæŒ‰ç½®ä¿¡åº¦ä»é«˜åˆ°ä½æ’åº
            3. æœ€é«˜ç½®ä¿¡åº¦çš„ç»“æœç”¨ç»¿è‰²æ˜¾ç¤ºï¼Œå…¶ä»–ç”¨ç™½è‰²
            4. ä¸æ·»åŠ èƒŒæ™¯æ¡†ï¼Œç®€æ´æ˜¾ç¤º
            5. æ ¼å¼ï¼š"ç±»åˆ«: ç½®ä¿¡åº¦%"
        """
        # è·å–åˆ†ç±»æ•°æ®
        classification_data = processed_data.get('classification', {})
        top_predictions = classification_data.get('top_predictions', [])
        
        if not top_predictions:
            return image
        
        # è·å–é…ç½®
        cls_config = self.config['classification']
        max_results = cls_config['max_results']
        start_x, start_y = cls_config['position']
        line_spacing = cls_config['line_spacing']
        show_bg = cls_config['show_background']
        
        # é™åˆ¶æ˜¾ç¤ºæ•°é‡
        display_predictions = top_predictions[:max_results]
        
        # è·å–å­—ä½“é…ç½®
        font = self.config['font']
        font_scale = self.config['font_scale']
        font_thickness = self.config['font_thickness']
        
        # éå†æ‰€æœ‰è¦æ˜¾ç¤ºçš„åˆ†ç±»ç»“æœ
        for i, (class_name, confidence) in enumerate(display_predictions):
            # æ„å»ºæ˜¾ç¤ºæ–‡æœ¬
            if confidence >= 0.01:  # å¤§äº1%çš„æ˜¾ç¤ºç™¾åˆ†æ¯”
                text = f"{class_name}: {confidence*100:.1f}%"
            else:  # å°äº1%çš„æ˜¾ç¤ºå°æ•°
                text = f"{class_name}: {confidence:.3f}"
            
            # è®¾ç½®é¢œè‰²ï¼šç¬¬ä¸€ä¸ªç»“æœç”¨ç»¿è‰²ï¼Œå…¶ä»–ç”¨ç™½è‰²
            if i == 0:
                color = cls_config['top_result_color']
            else:
                color = cls_config['other_result_color']
            
            # è®¡ç®—å½“å‰è¡Œä½ç½®
            current_y = start_y + i * line_spacing
            
            # ç¡®ä¿ä½ç½®åœ¨å›¾åƒèŒƒå›´å†…
            if current_y < 0 or current_y >= image.shape[0]:
                break
            
            if show_bg:
                # è®¡ç®—æ–‡æœ¬èƒŒæ™¯
                (text_width, text_height), baseline = cv2.getTextSize(
                    text, font, font_scale, font_thickness
                )
                
                # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
                bg_x1 = start_x - 5
                bg_y1 = current_y - text_height - 5
                bg_x2 = start_x + text_width + 5
                bg_y2 = current_y + 5
                
                if bg_y1 >= 0:
                    overlay = image.copy()
                    cv2.rectangle(overlay, (bg_x1, bg_y1), (bg_x2, bg_y2), 
                                 (0, 0, 0), -1)
                    image = cv2.addWeighted(overlay, 0.5, image, 0.5, 0)
            
            # ç›´æ¥ç»˜åˆ¶æ–‡æœ¬ï¼ˆæ ¹æ®é…ç½®å†³å®šæ˜¯å¦æœ‰èƒŒæ™¯ï¼‰
            cv2.putText(image, text, (start_x, current_y), 
                       font, font_scale, color, font_thickness, cv2.LINE_AA)
        
        return image
    
    # ============================================================================
    # å…³é”®ç‚¹æ£€æµ‹æ¸²æŸ“æ–¹æ³•ï¼ˆé€šç”¨ç‰ˆï¼‰
    # ============================================================================
    
    def _render_pose(self, image: np.ndarray, processed_data: Dict[str, Any], 
                    model_info: Dict[str, Any]) -> np.ndarray:
        """
        æ¸²æŸ“å…³é”®ç‚¹æ£€æµ‹ç»“æœï¼ˆé€šç”¨ï¼‰
        
        ä¸å‡è®¾ä»»ä½•ç‰¹å®šå…³é”®ç‚¹æ¨¡å‹ï¼Œæ ¹æ®å®é™…æ•°æ®åŠ¨æ€æ¸²æŸ“
        
        æ•°æ®ç»“æ„è¦æ±‚ï¼ˆprocessed_data['pose']ï¼‰ï¼š
            - boxes: [[x1,y1,x2,y2], ...]  # è¾¹ç•Œæ¡†åæ ‡
            - keypoints: [[[x,y], ...], ...]  # å…³é”®ç‚¹åæ ‡åˆ—è¡¨
            - keypoints_conf: [[0.9, 0.8, ...], ...]  # å…³é”®ç‚¹ç½®ä¿¡åº¦åˆ—è¡¨
            - confidences: [0.95, ...]  # è¾¹ç•Œæ¡†ç½®ä¿¡åº¦åˆ—è¡¨
            
        æ¸²æŸ“æ•ˆæœï¼š
            1. ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆæ˜¾ç¤ºç±»åˆ«å’Œç½®ä¿¡åº¦ï¼‰
            2. ç»˜åˆ¶å…³é”®ç‚¹ï¼ˆä¸åŒå…³é”®ç‚¹ä¸åŒé¢œè‰²ï¼‰
            3. ç»˜åˆ¶éª¨æ¶è¿æ¥ï¼ˆå¦‚æœé…ç½®ä¸­æœ‰ï¼‰
            4. ç¡®ä¿å…³é”®ç‚¹åœ¨è¾¹ç•Œæ¡†å†…ï¼ˆå¿…è¦æ—¶è¿›è¡Œé™åˆ¶ï¼‰
        """
        # è·å–å…³é”®ç‚¹æ•°æ®
        pose_data = processed_data.get('pose', {})
        boxes = pose_data.get('boxes', [])
        keypoints_list = pose_data.get('keypoints', [])
        keypoints_conf_list = pose_data.get('keypoints_conf', [])
        box_confidences = pose_data.get('confidences', [])
        
        if not boxes:
            return image
        
        # è·å–å›¾åƒå°ºå¯¸
        img_height, img_width = image.shape[:2]
        
        # è·å–é…ç½®
        pose_config = self.config['pose']
        bbox_color = pose_config['bbox_color']
        bbox_thickness = pose_config['bbox_thickness']
        keypoint_radius = pose_config['keypoint_radius']
        skeleton_thickness = pose_config['skeleton_thickness']
        skeleton_color = pose_config['skeleton_color']
        show_skeleton = pose_config['show_skeleton']
        
        # è·å–å…³é”®ç‚¹é¢œè‰²é…ç½®ï¼ˆå·²æ ¹æ®æ¨¡å‹ä¿¡æ¯åŠ¨æ€ç”Ÿæˆï¼‰
        keypoint_colors = pose_config.get('keypoint_colors', {})
        
        # è·å–éª¨æ¶è¿æ¥é…ç½®
        skeleton_connections = pose_config.get('skeleton_connections', [])
        
        # éå†æ‰€æœ‰æ£€æµ‹å¯¹è±¡
        for obj_idx, box in enumerate(boxes):
            if len(box) < 4:
                continue
            
            # æå–è¾¹ç•Œæ¡†åæ ‡
            x1, y1, x2, y2 = map(int, box[:4])
            
            # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨å›¾åƒèŒƒå›´å†…
            x1 = max(0, min(x1, img_width - 1))
            y1 = max(0, min(y1, img_height - 1))
            x2 = max(0, min(x2, img_width - 1))
            y2 = max(0, min(y2, img_height - 1))
            
            # è·å–è¾¹ç•Œæ¡†ç½®ä¿¡åº¦
            box_confidence = 0.0
            if obj_idx < len(box_confidences):
                box_confidence = box_confidences[obj_idx]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thickness)
            
            # åœ¨è¾¹ç•Œæ¡†ä¸Šæ·»åŠ æ ‡ç­¾
            label_text = "Object"
            if 'class_names' in model_info and len(model_info['class_names']) > 0:
                # å¦‚æœæœ‰ç±»åˆ«åç§°ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç±»åˆ«ï¼ˆå‡è®¾å…³é”®ç‚¹æ£€æµ‹é€šå¸¸æ˜¯å•ç±»åˆ«ï¼‰
                label_text = model_info['class_names'][0]
            
            # æ·»åŠ ç½®ä¿¡åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
            if box_confidence > 0:
                label_text = f"{label_text} {box_confidence:.2f}"
            
            # è®¡ç®—æ–‡æœ¬å¤§å°å¹¶ç»˜åˆ¶æ ‡ç­¾
            self._draw_label_on_box(image, label_text, x1, y1, bbox_color)
            
            # è·å–å½“å‰å¯¹è±¡çš„å…³é”®ç‚¹
            if obj_idx < len(keypoints_list):
                person_keypoints = keypoints_list[obj_idx]
                person_confidences = []
                if obj_idx < len(keypoints_conf_list):
                    person_confidences = keypoints_conf_list[obj_idx]
                
                # å¤„ç†å…³é”®ç‚¹
                valid_keypoints = []
                for kp_idx, kp in enumerate(person_keypoints):
                    if len(kp) >= 2:
                        kp_x, kp_y = float(kp[0]), float(kp[1])
                        
                        # å…³é”®ç‚¹ç½®ä¿¡åº¦
                        kp_conf = 1.0
                        if kp_idx < len(person_confidences):
                            kp_conf = float(person_confidences[kp_idx])
                        
                        # ç½®ä¿¡åº¦è¿‡æ»¤
                        if kp_conf < 0.1:
                            continue
                        
                        # ç¡®ä¿å…³é”®ç‚¹åœ¨å›¾åƒèŒƒå›´å†…ï¼Œå¹¶å°½é‡åœ¨è¾¹ç•Œæ¡†å†…
                        # ä½†ä¸ç¡¬æ€§é™åˆ¶åœ¨æ¡†å†…ï¼Œä¿æŒå§¿åŠ¿è‡ªç„¶æ€§
                        kp_x = max(0, min(kp_x, img_width - 1))
                        kp_y = max(0, min(kp_y, img_height - 1))
                        
                        # è®°å½•æœ‰æ•ˆå…³é”®ç‚¹
                        valid_keypoints.append({
                            'x': int(kp_x),
                            'y': int(kp_y),
                            'idx': kp_idx,
                            'conf': kp_conf
                        })
                
                # ç»˜åˆ¶éª¨æ¶è¿æ¥ï¼ˆå¦‚æœé…ç½®ä¸­æœ‰ä¸”éœ€è¦æ˜¾ç¤ºï¼‰
                if show_skeleton and skeleton_connections and len(valid_keypoints) > 0:
                    self._draw_skeleton_connections(image, valid_keypoints, 
                                                  skeleton_connections, skeleton_color, 
                                                  skeleton_thickness)
                
                # ç»˜åˆ¶å…³é”®ç‚¹
                for kp_info in valid_keypoints:
                    kp_x, kp_y, kp_idx, kp_conf = (kp_info['x'], kp_info['y'], 
                                                  kp_info['idx'], kp_info['conf'])
                    
                    # è·å–å…³é”®ç‚¹é¢œè‰²
                    color = keypoint_colors.get(kp_idx, self._generate_color(kp_idx))
                    
                    # ç»˜åˆ¶å…³é”®ç‚¹åœ†
                    cv2.circle(image, (kp_x, kp_y), keypoint_radius, color, -1)
                    
                    # æ˜¾ç¤ºå…³é”®ç‚¹åç§°ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
                    if pose_config.get('show_keypoint_names', False):
                        keypoint_names = pose_config.get('keypoint_names', {})
                        if kp_idx in keypoint_names:
                            kp_name = keypoint_names[kp_idx]
                            # ç»˜åˆ¶å…³é”®ç‚¹åç§°
                            cv2.putText(image, kp_name, 
                                       (kp_x + 10, kp_y + 10),
                                       self.config['font'], 0.3, color, 1, 
                                       cv2.LINE_AA)
                    
                    # å¯é€‰ï¼šç»˜åˆ¶å…³é”®ç‚¹IDï¼ˆè°ƒè¯•ç”¨ï¼‰
                    # cv2.putText(image, str(kp_idx), (kp_x+5, kp_y+5), 
                    #            self.config['font'], 0.3, color, 1)
        
        return image
    
    # ============================================================================
    # é€šç”¨è¾…åŠ©æ–¹æ³•
    # ============================================================================
    
    def _draw_label_on_box(self, image: np.ndarray, text: str, x: int, y: int, 
                          color: Tuple[int, int, int]) -> None:
        """
        åœ¨è¾¹ç•Œæ¡†ä¸Šç»˜åˆ¶æ ‡ç­¾ï¼ˆé€šç”¨æ–¹æ³•ï¼‰
        """
        font = self.config['font']
        font_scale = self.config['font_scale']
        font_thickness = self.config['font_thickness']
        
        (text_width, text_height), baseline = cv2.getTextSize(
            text, font, font_scale, font_thickness
        )
        
        # è®¡ç®—æ–‡æœ¬èƒŒæ™¯æ¡†ä½ç½®
        text_bg_x1 = x
        text_bg_y1 = max(0, y - text_height - 5)
        text_bg_x2 = x + text_width + 5
        text_bg_y2 = y
        
        # ç¡®ä¿æ–‡æœ¬èƒŒæ™¯æ¡†åœ¨å›¾åƒèŒƒå›´å†…
        img_height, img_width = image.shape[:2]
        text_bg_y1 = max(0, text_bg_y1)
        text_bg_x2 = min(text_bg_x2, img_width - 1)
        
        # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
        cv2.rectangle(image, (text_bg_x1, text_bg_y1), 
                     (text_bg_x2, text_bg_y2), color, -1)
        
        # ç»˜åˆ¶æ–‡æœ¬
        text_x = x + 2
        text_y = y - 3 if y - 3 > 0 else y + text_height
        
        cv2.putText(image, text, (text_x, text_y), 
                   font, font_scale, self.config['text_color'], 
                   font_thickness, cv2.LINE_AA)
    
    def _draw_skeleton_connections(self, image: np.ndarray, keypoints: List[Dict], 
                                 connections: List, color: Tuple[int, int, int], 
                                 thickness: int) -> None:
        """
        ç»˜åˆ¶éª¨æ¶è¿æ¥çº¿ï¼ˆé€šç”¨æ–¹æ³•ï¼‰
        
        Args:
            image: ç›®æ ‡å›¾åƒ
            keypoints: å…³é”®ç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯åŒ…å«'x','y','idx','conf'çš„å­—å…¸
            connections: è¿æ¥åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯(start_idx, end_idx)æˆ–[start_idx, end_idx]
            color: çº¿æ¡é¢œè‰²
            thickness: çº¿æ¡ç²—ç»†
        """
        # åˆ›å»ºç´¢å¼•åˆ°å…³é”®ç‚¹çš„æ˜ å°„
        kp_dict = {kp['idx']: kp for kp in keypoints}
        
        for connection in connections:
            # è§£æè¿æ¥é…ç½®
            if isinstance(connection, (list, tuple)) and len(connection) >= 2:
                start_idx, end_idx = connection[0], connection[1]
            elif isinstance(connection, dict):
                start_idx = connection.get('srt_kpt_id', -1)
                end_idx = connection.get('dst_kpt_id', -1)
            else:
                continue
            
            # è·å–èµ·å§‹å’Œç»“æŸå…³é”®ç‚¹
            start_kp = kp_dict.get(start_idx)
            end_kp = kp_dict.get(end_idx)
            
            # å¦‚æœä¸¤ä¸ªå…³é”®ç‚¹éƒ½å­˜åœ¨ä¸”ç½®ä¿¡åº¦è¶³å¤Ÿï¼Œç»˜åˆ¶è¿æ¥çº¿
            if start_kp and end_kp:
                if start_kp['conf'] > 0.1 and end_kp['conf'] > 0.1:
                    cv2.line(image, (start_kp['x'], start_kp['y']), 
                            (end_kp['x'], end_kp['y']), color, thickness)
    
    def draw_statistics(self, image: np.ndarray, stats: Dict[str, Any]) -> np.ndarray:
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œå³ä¸Šè§’ï¼‰
        
        Args:
            image: è¾“å…¥å›¾åƒ
            stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
            
        Returns:
            np.ndarray: æ·»åŠ äº†ç»Ÿè®¡ä¿¡æ¯çš„å›¾åƒ
        """
        if not stats:
            return image
        
        # æ„å»ºç»Ÿè®¡æ–‡æœ¬
        lines = []
        
        # æ·»åŠ åŸºç¡€ç»Ÿè®¡
        if 'detection_count' in stats:
            lines.append(f"Objects: {stats['detection_count']}")
        
        if 'avg_confidence' in stats and stats['avg_confidence'] > 0:
            lines.append(f"Conf: {stats['avg_confidence']:.2f}")
        
        if 'keypoint_count' in stats:
            lines.append(f"Keypoints: {stats['keypoint_count']}")
        
        if 'inference_time' in stats:
            lines.append(f"Time: {stats['inference_time']:.1f}ms")
        
        # åœ¨å›¾åƒå³ä¸Šè§’ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯
        if lines:
            start_x = image.shape[1] - 150  # å³ä¾§èµ·å§‹ä½ç½®
            start_y = 30
            line_spacing = 20
            
            font = self.config['font']
            font_scale = 0.4
            font_thickness = 1
            
            for i, line in enumerate(lines):
                y_pos = start_y + i * line_spacing
                if y_pos < image.shape[0]:
                    cv2.putText(image, line, (start_x, y_pos), 
                               font, font_scale, (255, 255, 255), 
                               font_thickness, cv2.LINE_AA)
        
        return image